{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8d9aeb",
   "metadata": {},
   "source": [
    "## 참고: https://hleecaster.com/ml-linear-regression-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24584ff",
   "metadata": {},
   "source": [
    "## 라이브러리 설치, 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18631f15",
   "metadata": {},
   "source": [
    "!pip3 install -U scikit-learn<br>\n",
    "!pip3 install pandas<br>\n",
    "!pip3 install numpy<br>\n",
    "!pip3 install matplotlib<br>\n",
    "!pip3 install statsmodels<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a912728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d835d",
   "metadata": {},
   "source": [
    "## 데이터 다운로드 (특별할인 판매)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6fe09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date weekday  busy_day  high_temperature  special_sales\n",
      "0  2002-08-05     Mon         0                28              1\n",
      "1  2002-08-06     Tue         0                24              0\n",
      "2  2002-08-07     Wed         1                26              0\n",
      "3  2002-08-08     Thu         0                24              0\n",
      "4  2002-08-09     Fri         0                23              0\n",
      "(21, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jmnote/zdata/master/logistic-regression/special-sales.csv')\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae03042",
   "metadata": {},
   "source": [
    "## Input, Feature 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbcf321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = df['special_sales']\n",
    "InputFeature = df[['busy_day','high_temperature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9edb19",
   "metadata": {},
   "source": [
    "## Keras Logit 모델 fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121e6d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 17:42:57.618969: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-06 17:42:57.619066: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='linear', input_shape=(2,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2abf85",
   "metadata": {},
   "source": [
    "## Keras 모델 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b1df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef88762",
   "metadata": {},
   "source": [
    "## Call-back 함수\n",
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84e8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath='-{epoch:03d}-{loss:.4f}-{accuracy:.4f}.hdf5',\n",
    "            monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Learning Rate 줄여나가기\n",
    "LR = ReduceLROnPlateau(monitor='loss',factor=0.8,patience=3, verbose=1, min_lr=1e-8)\n",
    "\n",
    "CALLBACK = [CP, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f681b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x=InputFeature, y=Label, epochs=100, shuffle=True, batch_size=3, callbacks=CALLBACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13beca2c",
   "metadata": {},
   "source": [
    "# Model Load 하기 전, hdf5 파일 이름 꼭 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13bdffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"-100-0.5806-0.7619.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facab60a",
   "metadata": {},
   "source": [
    "## FLASK 셋팅하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9874dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d583e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553c0c4",
   "metadata": {},
   "source": [
    "# FLASK API 구현부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c2c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/SpecialSale/<busy_day>/<high_temperature>')\n",
    "def PredictionSpecialSale(busy_day=None, high_temperature=None):\n",
    "    Input = pd.DataFrame({\n",
    "        'busy_day':[int(busy_day)],\n",
    "        'high_temperature':[float(high_temperature)]\n",
    "    })\n",
    "    \n",
    "    return str(model.predict(Input)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1437e7",
   "metadata": {},
   "source": [
    "# Flask, port 3000으로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55b97941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses (0.0.0.0)\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://127.0.0.1:3000\n",
      " * Running on http://10.186.27.58:3000 (Press CTRL+C to quit)\n",
      "2022-07-06 17:43:03.281909: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-06 17:43:03.317492: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "127.0.0.1 - - [06/Jul/2022 17:43:03] \"GET /SpecialSale/31/22424 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run(host='0.0.0.0', port=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc09cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
